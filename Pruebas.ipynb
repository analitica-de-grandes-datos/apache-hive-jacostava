{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37322a60-ebbb-45ef-ad1a-f59b58253aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import Magics, cell_magic, line_magic, magics_class\n",
    "from pexpect import spawn\n",
    "\n",
    "TIMEOUT = 300\n",
    "PROG = \"hive\"\n",
    "PROMPT = [\"\\r\\n    > \", \"\\r\\nhive> \"]\n",
    "QUIT = \"quit;\"\n",
    "\n",
    "\n",
    "@magics_class\n",
    "class Magic(Magics):\n",
    "    def __init__(self, shell):\n",
    "        super().__init__(shell)\n",
    "        self.app = spawn(PROG, timeout=60)\n",
    "        self.app.expect(PROMPT)\n",
    "\n",
    "    @cell_magic\n",
    "    def hive(self, line, cell):\n",
    "        cell_lines = [cell_line.strip() for cell_line in cell.split(\"\\n\")]\n",
    "        cell_lines = [cell_line for cell_line in cell_lines if cell_line != \"\"]\n",
    "        for cell_line in cell_lines:\n",
    "            self.app.sendline(cell_line)\n",
    "            self.app.expect(PROMPT, timeout=TIMEOUT)\n",
    "            output = self.app.before.decode()\n",
    "            output = output.replace(\"\\r\\n\", \"\\n\")\n",
    "            output = output.split(\"\\n\")\n",
    "            output = [output_line.strip() for output_line in output]\n",
    "            for output_line in output:\n",
    "                if output_line not in cell_lines:\n",
    "                    print(output_line)\n",
    "        return None\n",
    "\n",
    "    @line_magic\n",
    "    def quit(self, line):\n",
    "        self.app.sendline(QUIT)\n",
    "\n",
    "\n",
    "def load_ipython_extension(ip):\n",
    "    ip.register_magics(Magic(ip))\n",
    "\n",
    "\n",
    "load_ipython_extension(ip=get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3acd819e-2edc-433d-83f4-9c69e6066d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyFromLocal: `/tmp/data.tsv': File exists\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_02/data.tsv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c34d658-1488-4dc2-a566-19dc3f4a1f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   1 root supergroup        677 2023-05-31 02:45 /tmp/data.tsv\n",
      "drwxrwx---   - root supergroup          0 2023-05-30 16:19 /tmp/hadoop-yarn\n",
      "drwxrwxrwx   - root supergroup          0 2023-05-30 16:21 /tmp/hive\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2083c6-977c-423a-8dac-d0e99eb8225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm /tmp/data.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b8be9b-815b-4ee0-88d8-fc38b0dd2636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Time taken: 8.376 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "420d78af-225a-4722-99b4-2ed8b7e18f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Time taken: 0.671 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "CREATE TABLE data (\n",
    "letter STRING,\n",
    "date_event STRING,\n",
    "value INT\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY  '\\t';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ee07e9-71f9-4720-ac07-9426b9342151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data to table default.data\n",
      "OK\n",
      "Time taken: 0.759 seconds\n",
      "OK\n",
      "B\t1999-08-28\t14\n",
      "E\t1999-12-06\t12\n",
      "E\t1993-07-21\t17\n",
      "C\t1991-02-12\t13\n",
      "E\t1995-04-25\t16\n",
      "A\t1992-08-22\t14\n",
      "B\t1999-06-11\t12\n",
      "E\t1993-01-27\t13\n",
      "E\t1999-09-10\t11\n",
      "E\t1990-05-03\t16\n",
      "E\t1994-02-14\t5\n",
      "A\t1988-04-27\t12\n",
      "A\t1990-10-06\t10\n",
      "E\t1985-02-12\t16\n",
      "E\t1998-09-14\t16\n",
      "B\t1994-08-30\t17\n",
      "A\t1997-12-15\t13\n",
      "B\t1995-08-23\t10\n",
      "B\t1998-11-22\t13\n",
      "B\t1997-04-09\t14\n",
      "E\t1993-12-27\t18\n",
      "E\t1999-01-14\t15\n",
      "A\t1992-09-19\t18\n",
      "B\t1993-03-02\t14\n",
      "B\t1999-10-21\t13\n",
      "A\t1990-08-31\t12\n",
      "C\t1994-01-25\t6\n",
      "E\t1990-02-09\t18\n",
      "A\t1990-09-26\t14\n",
      "A\t1993-05-08\t16\n",
      "B\t1995-09-06\t14\n",
      "E\t1991-02-18\t14\n",
      "A\t1993-01-11\t14\n",
      "A\t1990-07-22\t18\n",
      "C\t1994-09-09\t15\n",
      "C\t1994-07-27\t7\n",
      "D\t1990-10-10\t15\n",
      "A\t1990-09-05\t11\n",
      "B\t1991-10-01\t15\n",
      "A\t1994-10-25\t13\n",
      "Time taken: 1.645 seconds, Fetched: 40 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "LOAD DATA INPATH '/tmp/data.tsv' OVERWRITE INTO TABLE data;\n",
    "SELECT * FROM data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2eebb39-7014-447a-943c-1beb55eb47b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230531174657_4d312f1b-d5c0-4bfe-919e-8ecb31d069d6\n",
      "Total jobs = 2\n",
      "Launching Job 1 out of 2\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685463534098_0002, Tracking URL = http://a0b990b2c7b2:8088/proxy/application_1685463534098_0002/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685463534098_0002\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-05-31 17:47:09,957 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-05-31 17:47:15,211 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.42 sec\n",
      "2023-05-31 17:47:21,466 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.83 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 830 msec\n",
      "Ended Job = job_1685463534098_0002\n",
      "Launching Job 2 out of 2\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685463534098_0003, Tracking URL = http://a0b990b2c7b2:8088/proxy/application_1685463534098_0003/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685463534098_0003\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2023-05-31 17:47:34,167 Stage-2 map = 0%,  reduce = 0%\n",
      "2023-05-31 17:47:39,378 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.77 sec\n",
      "2023-05-31 17:47:45,599 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 5.04 sec\n",
      "MapReduce Total cumulative CPU time: 5 seconds 40 msec\n",
      "Ended Job = job_1685463534098_0003\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.83 sec   HDFS Read: 7378 HDFS Write: 186 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 5.04 sec   HDFS Read: 5158 HDFS Write: 159 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 9 seconds 870 msec\n",
      "OK\n",
      "5\n",
      "6\n",
      "7\n",
      "10\n",
      "11\n",
      "Time taken: 49.622 seconds, Fetched: 5 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT DISTINCT(value)\n",
    "FROM data\n",
    "ORDER BY value LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf53e343-a78d-42f6-a3a3-645d8b491c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_04/data0.csv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58da2cf5-5e2d-4165-9da1-b6c7e5454b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_04/data1.csv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5523e8ac-0f38-4eaa-b1cb-8d583e481681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 items\n",
      "-rw-r--r--   1 root supergroup        677 2023-05-31 18:31 /tmp/data.tsv\n",
      "-rw-r--r--   1 root supergroup        397 2023-05-31 18:31 /tmp/data0.csv\n",
      "-rw-r--r--   1 root supergroup        282 2023-05-31 18:32 /tmp/data1.csv\n",
      "drwxrwx---   - root supergroup          0 2023-05-30 16:19 /tmp/hadoop-yarn\n",
      "drwxrwxrwx   - root supergroup          0 2023-05-30 16:21 /tmp/hive\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca92ca78-5096-4ccf-b694-dc139db36aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Time taken: 0.079 seconds\n",
      "OK\n",
      "Time taken: 0.068 seconds\n",
      "Loading data to table default.tbl0\n",
      "OK\n",
      "Time taken: 0.231 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS tbl0;\n",
    "CREATE TABLE tbl0 (\n",
    "    c1 INT,\n",
    "    c2 STRING,\n",
    "    c3 INT,\n",
    "    c4 DATE,\n",
    "    c5 ARRAY<CHAR(1)>, \n",
    "    c6 MAP<STRING, INT>\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ','\n",
    "COLLECTION ITEMS TERMINATED BY ':'\n",
    "MAP KEYS TERMINATED BY '#'\n",
    "LINES TERMINATED BY '\\n';\n",
    "LOAD DATA INPATH '/tmp/data0.csv' INTO TABLE tbl0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e239234b-f2b7-4460-85ee-d24497ac803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "data\n",
      "tbl0\n",
      "Time taken: 0.045 seconds, Fetched: 2 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SHOW TABLES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c6e8451b-d790-41cd-8937-e31801b2e8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230531223206_871e5d43-516b-4ecc-aa48-ccda0f88a75a\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685463534098_0008, Tracking URL = http://a0b990b2c7b2:8088/proxy/application_1685463534098_0008/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685463534098_0008\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-05-31 22:32:12,885 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-05-31 22:32:25,527 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.82 sec\n",
      "2023-05-31 22:32:30,762 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 7.13 sec\n",
      "MapReduce Total cumulative CPU time: 7 seconds 130 msec\n",
      "Ended Job = job_1685463534098_0008\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 7.13 sec   HDFS Read: 12856 HDFS Write: 717 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 7 seconds 130 msec\n",
      "OK\n",
      "2014\ta\t1\n",
      "2014\td\t1\n",
      "2014\te\t1\n",
      "2014\tb\t1\n",
      "2014\td\t1\n",
      "2015\ta\t1\n",
      "2015\tc\t1\n",
      "2015\ta\t1\n",
      "2015\tb\t1\n",
      "2015\tc\t1\n",
      "2015\td\t1\n",
      "2015\te\t1\n",
      "2015\ta\t1\n",
      "2015\tc\t1\n",
      "2015\td\t1\n",
      "2015\te\t1\n",
      "2016\tc\t1\n",
      "2016\td\t1\n",
      "2016\te\t1\n",
      "2016\ta\t2\n",
      "2016\tb\t1\n",
      "2016\tc\t2\n",
      "2016\td\t2\n",
      "2016\te\t2\n",
      "2017\ta\t1\n",
      "2017\tb\t1\n",
      "2017\tc\t1\n",
      "2017\te\t1\n",
      "2018\ta\t1\n",
      "2018\td\t1\n",
      "Time taken: 26.287 seconds, Fetched: 30 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT SUBSTRING(c4,0,4) as c4, letras, count(1) FROM tbl0\n",
    "LATERAL VIEW\n",
    "    explode(c5) tbl0 as letras\n",
    "GROUP BY c4, letras;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "520a24d1-e4f1-4413-b018-f69932d84b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230531213843_eab47cdf-4e55-4069-91cd-184bbe68bab3\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685463534098_0006, Tracking URL = http://a0b990b2c7b2:8088/proxy/application_1685463534098_0006/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685463534098_0006\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-05-31 21:38:48,784 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-05-31 21:38:55,126 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 4.16 sec\n",
      "2023-05-31 21:39:01,382 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.65 sec\n",
      "MapReduce Total cumulative CPU time: 6 seconds 650 msec\n",
      "Ended Job = job_1685463534098_0006\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.65 sec   HDFS Read: 9398 HDFS Write: 157 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 6 seconds 650 msec\n",
      "OK\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "Time taken: 18.683 seconds, Fetched: 5 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT DISTINCT(letras) as let\n",
    "FROM(\n",
    "SELECT\n",
    "explode(c5) as letras\n",
    "FROM\n",
    "tbl0\n",
    ") w;\n",
    "ORDER BY let"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15eabccc-7b22-47b9-a51b-046f9f9ade1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILED: ClassCastException org.apache.hadoop.hive.serde2.objectinspector.StandardListObjectInspector cannot be cast to org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT explode(split(c5, ',')) AS word FROM tbl0 LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f0d0d-5802-4365-9e68-2334d7e10b33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
