{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37322a60-ebbb-45ef-ad1a-f59b58253aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import Magics, cell_magic, line_magic, magics_class\n",
    "from pexpect import spawn\n",
    "\n",
    "TIMEOUT = 300\n",
    "PROG = \"hive\"\n",
    "PROMPT = [\"\\r\\n    > \", \"\\r\\nhive> \"]\n",
    "QUIT = \"quit;\"\n",
    "\n",
    "\n",
    "@magics_class\n",
    "class Magic(Magics):\n",
    "    def __init__(self, shell):\n",
    "        super().__init__(shell)\n",
    "        self.app = spawn(PROG, timeout=60)\n",
    "        self.app.expect(PROMPT)\n",
    "\n",
    "    @cell_magic\n",
    "    def hive(self, line, cell):\n",
    "        cell_lines = [cell_line.strip() for cell_line in cell.split(\"\\n\")]\n",
    "        cell_lines = [cell_line for cell_line in cell_lines if cell_line != \"\"]\n",
    "        for cell_line in cell_lines:\n",
    "            self.app.sendline(cell_line)\n",
    "            self.app.expect(PROMPT, timeout=TIMEOUT)\n",
    "            output = self.app.before.decode()\n",
    "            output = output.replace(\"\\r\\n\", \"\\n\")\n",
    "            output = output.split(\"\\n\")\n",
    "            output = [output_line.strip() for output_line in output]\n",
    "            for output_line in output:\n",
    "                if output_line not in cell_lines:\n",
    "                    print(output_line)\n",
    "        return None\n",
    "\n",
    "    @line_magic\n",
    "    def quit(self, line):\n",
    "        self.app.sendline(QUIT)\n",
    "\n",
    "\n",
    "def load_ipython_extension(ip):\n",
    "    ip.register_magics(Magic(ip))\n",
    "\n",
    "\n",
    "load_ipython_extension(ip=get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd819e-2edc-433d-83f4-9c69e6066d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_02/data.tsv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34d658-1488-4dc2-a566-19dc3f4a1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2083c6-977c-423a-8dac-d0e99eb8225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm /tmp/data.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8be9b-815b-4ee0-88d8-fc38b0dd2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d78af-225a-4722-99b4-2ed8b7e18f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "CREATE TABLE data (\n",
    "letter STRING,\n",
    "date_event STRING,\n",
    "value INT\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY  '\\t';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee07e9-71f9-4720-ac07-9426b9342151",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "LOAD DATA INPATH '/tmp/data.tsv' OVERWRITE INTO TABLE data;\n",
    "SELECT * FROM data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eebb39-7014-447a-943c-1beb55eb47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT DISTINCT(value)\n",
    "FROM data\n",
    "ORDER BY value LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a24d1-e4f1-4413-b018-f69932d84b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT DISTINCT(letras) as let\n",
    "FROM(\n",
    "SELECT\n",
    "explode(c5) as letras\n",
    "FROM\n",
    "tbl0\n",
    ") w;\n",
    "ORDER BY let"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf53e343-a78d-42f6-a3a3-645d8b491c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_04/data0.csv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58da2cf5-5e2d-4165-9da1-b6c7e5454b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_04/data1.csv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523e8ac-0f38-4eaa-b1cb-8d583e481681",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92ca78-5096-4ccf-b694-dc139db36aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS tbl0;\n",
    "CREATE TABLE tbl0 (\n",
    "    c1 INT,\n",
    "    c2 STRING,\n",
    "    c3 INT,\n",
    "    c4 DATE,\n",
    "    c5 ARRAY<CHAR(1)>, \n",
    "    c6 MAP<STRING, INT>\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ','\n",
    "COLLECTION ITEMS TERMINATED BY ':'\n",
    "MAP KEYS TERMINATED BY '#'\n",
    "LINES TERMINATED BY '\\n';\n",
    "LOAD DATA INPATH '/tmp/data0.csv' INTO TABLE tbl0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e239234b-f2b7-4460-85ee-d24497ac803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SHOW TABLES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908264f-a6b4-429a-86a8-48d013b0ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT DISTINCT(SUBSTRING(c4,0,4)) as c4 FROM tbl0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eabccc-7b22-47b9-a51b-046f9f9ade1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT explode(split(c5, ',')) AS word FROM tbl0 LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0197317-70fc-4206-8015-dfc2f1e579c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT otro, letras, count(*) as total FROM(\n",
    "SELECT SUBSTRING(c4,0,4) as otro, letras FROM tbl0\n",
    "LATERAL VIEW\n",
    "    explode(c5) tbl0 as letras\n",
    "ORDER BY otro, letras\n",
    ") w\n",
    "GROUP BY otro, letras;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5742993-e834-4176-ae58-fcfb6c208231",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT COLLECT_SET(UPPER(letras)) FROM tbl0\n",
    "LATERAL VIEW\n",
    "    explode(c5) tbl0 as letras;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cad85c0-d857-4086-ad6a-4a5b099bb9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT UPPER(CONCAT_WS(':',c5)) FROM tbl0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1553665-873d-467b-9d6a-e624f64a3ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT c2, COLLECT_SET(c1) FROM tbl0\n",
    "GROUP BY c2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f6040-afe3-428e-9969-62c84b1bd636",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT c2, COLLECT_SET(c1) as numeros FROM tbl0\n",
    "GROUP BY c2\n",
    "ORDER BY c2, numeros;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df88a2-eb3b-468e-b458-1e19558fecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "select c2 letra, sum(unal.value)\n",
    "from tbl0\n",
    "lateral view explode(c6) unal AS key, value\n",
    "group by c2;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbaa220d-1e94-484c-8e27-0e8fbd168192",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_09/data0.csv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6985544-36f3-4271-9fe9-abd578e91a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Time taken: 0.028 seconds\n",
      "OK\n",
      "Time taken: 0.079 seconds\n",
      "Loading data to table default.tbl0\n",
      "OK\n",
      "Time taken: 0.438 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS tbl0;\n",
    "CREATE TABLE tbl0 (\n",
    "    c1 INT,\n",
    "    c2 STRING,\n",
    "    c3 INT,\n",
    "    c4 DATE,\n",
    "    c5 ARRAY<CHAR(1)>, \n",
    "    c6 MAP<STRING, INT>\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ','\n",
    "COLLECTION ITEMS TERMINATED BY ':'\n",
    "MAP KEYS TERMINATED BY '#'\n",
    "LINES TERMINATED BY '\\n';\n",
    "LOAD DATA INPATH '/tmp/data0.csv' INTO TABLE tbl0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0da664fe-85ea-4c6f-a9ab-3d1d9344c176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "1\tD\t4\t2016-06-25\t[\"a\",\"e\",\"c\",\"d\"]\t{\"bb\":10,\"dd\":20,\"cc\":40}\n",
      "2\tC\t4\t2015-05-14\t[\"a\",\"c\"]\t{\"dd\":40,\"bb\":20,\"cc\":10}\n",
      "3\tD\t6\t2014-12-26\t[\"b\",\"d\"]\t{\"aa\":10,\"bb\":40}\n",
      "4\tD\t5\t2016-06-25\t[\"a\",\"c\",\"e\",\"b\",\"d\"]\t{\"bb\":40,\"dd\":20,\"aa\":10,\"cc\":30}\n",
      "5\tC\t7\t2016-05-23\t[\"d\",\"e\",\"c\"]\t{\"cc\":10,\"aa\":20}\n",
      "6\tA\t2\t2018-06-14\t[\"a\",\"d\"]\t{\"aa\":20}\n",
      "7\tB\t3\t2014-12-22\t[\"a\",\"e\",\"d\"]\t{\"cc\":20}\n",
      "8\tC\t6\t2015-08-20\t[\"d\",\"a\",\"c\",\"e\"]\t{\"cc\":10,\"aa\":20}\n",
      "9\tB\t3\t2017-12-08\t[\"b\",\"a\",\"c\",\"e\"]\t{\"cc\":40,\"dd\":10,\"aa\":30,\"bb\":20}\n",
      "10\tB\t7\t2015-07-28\t[\"c\",\"d\",\"e\",\"a\",\"b\"]\t{\"aa\":10,\"dd\":40,\"cc\":30}\n",
      "Time taken: 0.155 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "select * from tbl0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a5817-bfe1-4da0-8fac-f62025cd01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm /tmp/data1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b342af5e-99f1-4e5d-a867-6df659becbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_09/data1.csv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a734fca-b51f-4f9b-bd7e-af0699eae640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   1 root supergroup        282 2023-06-03 19:22 /tmp/data1.csv\n",
      "drwxrwx---   - root supergroup          0 2023-06-03 19:18 /tmp/hadoop-yarn\n",
      "drwxrwxrwx   - root supergroup          0 2023-06-03 19:21 /tmp/hive\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059273fc-8868-48e7-9d9c-35cc10385c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Time taken: 6.471 seconds\n",
      "OK\n",
      "Time taken: 0.631 seconds\n",
      "Loading data to table default.tbl1\n",
      "OK\n",
      "Time taken: 1.036 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS tbl1;\n",
    "CREATE TABLE tbl1 (\n",
    "    c1 INT,\n",
    "    c2 INT,\n",
    "    c3 STRING,\n",
    "    c4 MAP<STRING, INT>\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ','\n",
    "COLLECTION ITEMS TERMINATED BY ':'\n",
    "MAP KEYS TERMINATED BY '#'\n",
    "LINES TERMINATED BY '\\n';\n",
    "LOAD DATA INPATH '/tmp/data1.csv' INTO TABLE tbl1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9db2e5f9-f6b2-4a59-ad6a-b80c7a1ade06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "Time taken: 1.125 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "select c1 from tbl1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec07421d-da87-47d8-9f28-b80967b9d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_10/data.tsv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629f6e7-768f-4c40-bc74-4efd9c8a9ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2dba805-9256-4302-9f21-94ce61aa0d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Time taken: 0.018 seconds\n",
      "OK\n",
      "Time taken: 0.098 seconds\n",
      "Loading data to table default.t0\n",
      "OK\n",
      "Time taken: 0.287 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS t0;\n",
    "CREATE TABLE t0 (\n",
    "    c1 STRING,\n",
    "    c2 ARRAY<CHAR(1)>, \n",
    "    c3 MAP<STRING, INT>\n",
    "    )\n",
    "    ROW FORMAT DELIMITED \n",
    "        FIELDS TERMINATED BY '\\t'\n",
    "        COLLECTION ITEMS TERMINATED BY ','\n",
    "        MAP KEYS TERMINATED BY '#'\n",
    "        LINES TERMINATED BY '\\n';\n",
    "LOAD DATA INPATH '/tmp/data.tsv' INTO TABLE t0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09259c6b-4447-48d4-9d5c-f82cdb5a5238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230603195136_e82f3d37-0b35-4882-90c7-10b89564197d\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685819908924_0003, Tracking URL = http://e29ee468bf5f:8088/proxy/application_1685819908924_0003/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685819908924_0003\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 19:51:41,568 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-06-03 19:51:46,729 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.26 sec\n",
      "2023-06-03 19:51:53,046 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.64 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 640 msec\n",
      "Ended Job = job_1685819908924_0003\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.64 sec   HDFS Read: 12887 HDFS Write: 277 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 4 seconds 640 msec\n",
      "OK\n",
      "aaa\t13\n",
      "bbb\t16\n",
      "ccc\t23\n",
      "ddd\t23\n",
      "eee\t15\n",
      "fff\t20\n",
      "ggg\t13\n",
      "hhh\t16\n",
      "iii\t18\n",
      "jjj\t18\n",
      "Time taken: 18.666 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "select unal.key, count(1)\n",
    "from t0\n",
    "lateral view explode(c3) unal AS key, value\n",
    "group by unal.key;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18c1a5fa-c616-4146-b3af-8bc3997cd4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "E\t3\t5\n",
      "A\t3\t4\n",
      "B\t4\t4\n",
      "A\t2\t4\n",
      "C\t4\t4\n",
      "A\t2\t5\n",
      "A\t3\t6\n",
      "B\t2\t3\n",
      "E\t4\t6\n",
      "B\t4\t6\n",
      "C\t4\t5\n",
      "C\t4\t3\n",
      "D\t4\t5\n",
      "E\t2\t3\n",
      "B\t2\t5\n",
      "D\t2\t4\n",
      "E\t3\t6\n",
      "D\t2\t3\n",
      "E\t4\t3\n",
      "E\t2\t3\n",
      "E\t2\t3\n",
      "E\t3\t3\n",
      "D\t3\t3\n",
      "A\t3\t5\n",
      "E\t2\t6\n",
      "E\t3\t6\n",
      "A\t3\t3\n",
      "E\t3\t5\n",
      "A\t2\t5\n",
      "C\t4\t6\n",
      "A\t2\t5\n",
      "D\t2\t6\n",
      "E\t2\t4\n",
      "B\t3\t6\n",
      "B\t3\t5\n",
      "D\t2\t3\n",
      "B\t2\t5\n",
      "C\t4\t3\n",
      "E\t2\t3\n",
      "E\t3\t3\n",
      "Time taken: 0.134 seconds, Fetched: 40 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "select c1, size(c2) size_c2, size(c3) size_c3 from t0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2e73bba-9c34-4f52-b875-2b94f00c248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILED: SemanticException [Error 10004]: Line 10:9 Invalid table alias or column reference 'c2': (possible column names are: key)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "select \n",
    "    explode(c2) as c2, unal.key \n",
    "    from(\n",
    "        select \n",
    "        unal.key\n",
    "    from t0\n",
    "    lateral view explode(c3) unal AS key, value\n",
    "    order by unal.key\n",
    ") w\n",
    "group by c2, unal.key;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df254046-f855-4f8f-90fe-d7b21c8ea087",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "select c2, unal.key\n",
    "from t0\n",
    "lateral view explode(c3) unal AS key, value\n",
    "order by unal.key;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98506a67-5d34-4382-81ef-cbdeaf967da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "select unal\n",
    "from t0\n",
    "lateral view explode(c2) t0 as unal\n",
    "order by unal;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f365f0f-dc00-49c6-a1dd-e5ead3718db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230603205155_8301b923-4e9f-48dc-ac7c-ae84c025e444\n",
      "Total jobs = 2\n",
      "Launching Job 1 out of 2\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685819908924_0013, Tracking URL = http://e29ee468bf5f:8088/proxy/application_1685819908924_0013/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685819908924_0013\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 20:52:02,438 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-06-03 20:52:06,568 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.86 sec\n",
      "2023-06-03 20:52:11,768 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.32 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 320 msec\n",
      "Ended Job = job_1685819908924_0013\n",
      "Launching Job 2 out of 2\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685819908924_0014, Tracking URL = http://e29ee468bf5f:8088/proxy/application_1685819908924_0014/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685819908924_0014\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 20:52:23,598 Stage-2 map = 0%,  reduce = 0%\n",
      "2023-06-03 20:52:28,828 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.2 sec\n",
      "2023-06-03 20:52:35,057 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 5.39 sec\n",
      "MapReduce Total cumulative CPU time: 5 seconds 390 msec\n",
      "Ended Job = job_1685819908924_0014\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.32 sec   HDFS Read: 12382 HDFS Write: 1776 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 5.39 sec   HDFS Read: 7876 HDFS Write: 1500 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 9 seconds 710 msec\n",
      "OK\n",
      "a\taaa\t5\n",
      "a\tbbb\t7\n",
      "a\tccc\t13\n",
      "a\tddd\t13\n",
      "a\teee\t7\n",
      "a\tfff\t10\n",
      "a\tggg\t8\n",
      "a\thhh\t8\n",
      "a\tiii\t7\n",
      "a\tjjj\t10\n",
      "b\taaa\t4\n",
      "b\tbbb\t7\n",
      "b\tccc\t5\n",
      "b\tddd\t7\n",
      "b\teee\t5\n",
      "b\tfff\t8\n",
      "b\tggg\t4\n",
      "b\thhh\t7\n",
      "b\tiii\t7\n",
      "b\tjjj\t5\n",
      "c\taaa\t5\n",
      "c\tbbb\t4\n",
      "c\tccc\t12\n",
      "c\tddd\t9\n",
      "c\teee\t6\n",
      "c\tfff\t8\n",
      "c\tggg\t7\n",
      "c\thhh\t7\n",
      "c\tiii\t8\n",
      "c\tjjj\t8\n",
      "d\taaa\t4\n",
      "d\tbbb\t6\n",
      "d\tccc\t7\n",
      "d\tddd\t5\n",
      "d\teee\t6\n",
      "d\tfff\t8\n",
      "d\tggg\t6\n",
      "d\thhh\t4\n",
      "d\tiii\t9\n",
      "d\tjjj\t8\n",
      "e\taaa\t3\n",
      "e\tbbb\t8\n",
      "e\tccc\t9\n",
      "e\tddd\t7\n",
      "e\teee\t7\n",
      "e\tfff\t9\n",
      "e\tggg\t4\n",
      "e\thhh\t4\n",
      "e\tiii\t8\n",
      "e\tjjj\t3\n",
      "f\taaa\t8\n",
      "f\tbbb\t10\n",
      "f\tccc\t13\n",
      "f\tddd\t17\n",
      "f\teee\t11\n",
      "f\tfff\t11\n",
      "f\tggg\t9\n",
      "f\thhh\t10\n",
      "f\tiii\t10\n",
      "f\tjjj\t12\n",
      "g\taaa\t3\n",
      "g\tbbb\t3\n",
      "g\tccc\t6\n",
      "g\tddd\t5\n",
      "g\teee\t4\n",
      "g\tfff\t5\n",
      "g\tggg\t4\n",
      "g\thhh\t3\n",
      "g\tiii\t4\n",
      "g\tjjj\t6\n",
      "Time taken: 40.232 seconds, Fetched: 70 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "select letra, unal.key, count(1) \n",
    "from(\n",
    "select letra, c3\n",
    "from t0\n",
    "lateral view explode(c2) t0 as letra\n",
    "order by letra) w\n",
    "lateral view explode(c3) unal AS key, value\n",
    "group by letra, unal.key;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f11517fd-e8e7-4343-b672-6eda915295c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230603210955_bcf472cd-bea9-43dc-b5b8-8465b1c47f0c\n",
      "Total jobs = 1\n",
      "2023-06-03 21:10:03\tStarting to launch local task to process map join;\tmaximum memory = 477626368\n",
      "2023-06-03 21:10:05\tDump the side-table for tag: 1 with group count: 10 into file: file:/tmp/root/091c5dca-dfbb-4e37-a694-7faa28857a27/hive_2023-06-03_21-09-55_755_721422163089084542-1/-local-10004/HashTable-Stage-3/MapJoin-mapfile11--.hashtable\n",
      "2023-06-03 21:10:05\tUploaded 1 File to: file:/tmp/root/091c5dca-dfbb-4e37-a694-7faa28857a27/hive_2023-06-03_21-09-55_755_721422163089084542-1/-local-10004/HashTable-Stage-3/MapJoin-mapfile11--.hashtable (673 bytes)\n",
      "2023-06-03 21:10:05\tEnd of local task; Time Taken: 1.79 sec.\n",
      "Execution completed successfully\n",
      "MapredLocal task succeeded\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "Starting Job = job_1685819908924_0016, Tracking URL = http://e29ee468bf5f:8088/proxy/application_1685819908924_0016/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685819908924_0016\n",
      "Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0\n",
      "2023-06-03 21:10:13,916 Stage-3 map = 0%,  reduce = 0%\n",
      "2023-06-03 21:10:19,079 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.03 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 30 msec\n",
      "Ended Job = job_1685819908924_0016\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-3: Map: 1   Cumulative CPU: 4.03 sec   HDFS Read: 7527 HDFS Write: 448 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 4 seconds 30 msec\n",
      "OK\n",
      "1\tD\t{\"A\":0,\"B\":4,\"C\":1,\"D\":3,\"E\":5}\n",
      "2\tC\t{\"A\":4,\"B\":1,\"C\":0,\"D\":5,\"E\":2}\n",
      "3\tD\t{\"A\":5,\"B\":4,\"C\":3,\"D\":1,\"E\":0}\n",
      "4\tD\t{\"A\":2,\"B\":4,\"C\":3,\"D\":5,\"E\":1}\n",
      "5\tC\t{\"A\":4,\"B\":0,\"C\":2,\"D\":5,\"E\":3}\n",
      "6\tA\t{\"A\":4,\"B\":5,\"C\":1,\"D\":2,\"E\":3}\n",
      "7\tB\t{\"A\":0,\"B\":5,\"C\":2,\"D\":4,\"E\":3}\n",
      "8\tC\t{\"A\":4,\"B\":2,\"C\":5,\"D\":3,\"E\":0}\n",
      "9\tB\t{\"A\":1,\"B\":4,\"C\":2,\"D\":5,\"E\":3}\n",
      "10\tB\t{\"A\":2,\"B\":3,\"C\":4,\"D\":1,\"E\":0}\n",
      "Time taken: 25.439 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "select t0.c1, t0.c2, t1.c4 from tbl0 t0\n",
    "join (\n",
    "select c1, c4 from tbl1\n",
    ") t1\n",
    "on (t0.c1 = t1.c1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f79b7740-f8e2-4695-b8dd-418bef311d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230603212256_c832473f-29c0-4ae4-9fb6-d5f838c421f2\n",
      "Total jobs = 2\n",
      "Launching Job 1 out of 2\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685819908924_0025, Tracking URL = http://e29ee468bf5f:8088/proxy/application_1685819908924_0025/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685819908924_0025\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 21:23:05,155 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-06-03 21:23:11,503 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 4.51 sec\n",
      "2023-06-03 21:23:17,709 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.66 sec\n",
      "MapReduce Total cumulative CPU time: 6 seconds 660 msec\n",
      "Ended Job = job_1685819908924_0025\n",
      "2023-06-03 21:23:26\tStarting to launch local task to process map join;\tmaximum memory = 477626368\n",
      "2023-06-03 21:23:27\tDump the side-table for tag: 0 with group count: 10 into file: file:/tmp/root/091c5dca-dfbb-4e37-a694-7faa28857a27/hive_2023-06-03_21-22-56_273_2792587058312229809-1/-local-10005/HashTable-Stage-3/MapJoin-mapfile60--.hashtable\n",
      "2023-06-03 21:23:27\tUploaded 1 File to: file:/tmp/root/091c5dca-dfbb-4e37-a694-7faa28857a27/hive_2023-06-03_21-22-56_273_2792587058312229809-1/-local-10005/HashTable-Stage-3/MapJoin-mapfile60--.hashtable (460 bytes)\n",
      "2023-06-03 21:23:27\tEnd of local task; Time Taken: 1.673 sec.\n",
      "Execution completed successfully\n",
      "MapredLocal task succeeded\n",
      "Launching Job 2 out of 2\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685819908924_0026, Tracking URL = http://e29ee468bf5f:8088/proxy/application_1685819908924_0026/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685819908924_0026\n",
      "Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 21:23:37,062 Stage-3 map = 0%,  reduce = 0%\n",
      "2023-06-03 21:23:42,283 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.9 sec\n",
      "2023-06-03 21:23:48,475 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.07 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 70 msec\n",
      "Ended Job = job_1685819908924_0026\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.66 sec   HDFS Read: 10627 HDFS Write: 1146 SUCCESS\n",
      "Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.07 sec   HDFS Read: 10272 HDFS Write: 268 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 10 seconds 730 msec\n",
      "OK\n",
      "1\tD\t3\n",
      "2\tC\t0\n",
      "3\tD\t1\n",
      "4\tD\t5\n",
      "5\tC\t2\n",
      "6\tA\t4\n",
      "7\tB\t5\n",
      "8\tC\t5\n",
      "9\tB\t4\n",
      "10\tB\t3\n",
      "Time taken: 53.275 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "select t0.c1, t0.c2, t1.value from tbl0 t0\n",
    "join (\n",
    "select c1, unal.key, unal.value from tbl1\n",
    "lateral view explode(c4) unal AS key, value\n",
    "order by unal.key\n",
    ") t1\n",
    "on (t0.c1 = t1.c1 and t0.c2 = t1.key)\n",
    "order by t0.c1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c63cf5c6-648c-4247-a6dd-c9ada47879a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230603214245_031c2a27-e448-4a25-9321-b4ef6294e6e4\n",
      "Total jobs = 2\n",
      "Launching Job 1 out of 2\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685819908924_0029, Tracking URL = http://e29ee468bf5f:8088/proxy/application_1685819908924_0029/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685819908924_0029\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 21:42:52,498 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-06-03 21:42:57,670 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.04 sec\n",
      "2023-06-03 21:43:03,828 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.45 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 450 msec\n",
      "Ended Job = job_1685819908924_0029\n",
      "Launching Job 2 out of 2\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685819908924_0030, Tracking URL = http://e29ee468bf5f:8088/proxy/application_1685819908924_0030/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685819908924_0030\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 21:43:16,986 Stage-2 map = 0%,  reduce = 0%\n",
      "2023-06-03 21:43:22,235 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.86 sec\n",
      "2023-06-03 21:43:28,420 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.83 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 830 msec\n",
      "Ended Job = job_1685819908924_0030\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.45 sec   HDFS Read: 12382 HDFS Write: 1776 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.83 sec   HDFS Read: 7876 HDFS Write: 1500 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 9 seconds 280 msec\n",
      "OK\n",
      "a\taaa\t5\n",
      "a\tbbb\t7\n",
      "a\tccc\t13\n",
      "a\tddd\t13\n",
      "a\teee\t7\n",
      "a\tfff\t10\n",
      "a\tggg\t8\n",
      "a\thhh\t8\n",
      "a\tiii\t7\n",
      "a\tjjj\t10\n",
      "b\taaa\t4\n",
      "b\tbbb\t7\n",
      "b\tccc\t5\n",
      "b\tddd\t7\n",
      "b\teee\t5\n",
      "b\tfff\t8\n",
      "b\tggg\t4\n",
      "b\thhh\t7\n",
      "b\tiii\t7\n",
      "b\tjjj\t5\n",
      "c\taaa\t5\n",
      "c\tbbb\t4\n",
      "c\tccc\t12\n",
      "c\tddd\t9\n",
      "c\teee\t6\n",
      "c\tfff\t8\n",
      "c\tggg\t7\n",
      "c\thhh\t7\n",
      "c\tiii\t8\n",
      "c\tjjj\t8\n",
      "d\taaa\t4\n",
      "d\tbbb\t6\n",
      "d\tccc\t7\n",
      "d\tddd\t5\n",
      "d\teee\t6\n",
      "d\tfff\t8\n",
      "d\tggg\t6\n",
      "d\thhh\t4\n",
      "d\tiii\t9\n",
      "d\tjjj\t8\n",
      "e\taaa\t3\n",
      "e\tbbb\t8\n",
      "e\tccc\t9\n",
      "e\tddd\t7\n",
      "e\teee\t7\n",
      "e\tfff\t9\n",
      "e\tggg\t4\n",
      "e\thhh\t4\n",
      "e\tiii\t8\n",
      "e\tjjj\t3\n",
      "f\taaa\t8\n",
      "f\tbbb\t10\n",
      "f\tccc\t13\n",
      "f\tddd\t17\n",
      "f\teee\t11\n",
      "f\tfff\t11\n",
      "f\tggg\t9\n",
      "f\thhh\t10\n",
      "f\tiii\t10\n",
      "f\tjjj\t12\n",
      "g\taaa\t3\n",
      "g\tbbb\t3\n",
      "g\tccc\t6\n",
      "g\tddd\t5\n",
      "g\teee\t4\n",
      "g\tfff\t5\n",
      "g\tggg\t4\n",
      "g\thhh\t3\n",
      "g\tiii\t4\n",
      "g\tjjj\t6\n",
      "Time taken: 44.818 seconds, Fetched: 70 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "select letra, unal.key, count(1) \n",
    "from(\n",
    "select letra, c3\n",
    "from t0\n",
    "lateral view explode(c2) t0 as letra\n",
    "order by letra) w\n",
    "lateral view explode(c3) unal AS key, value\n",
    "group by letra, unal.key;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b02ab771-40ff-4cbf-9515-704f47cc5092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230603214148_ce45f7a5-e8ea-4c15-94a2-06de3818ef47\n",
      "Total jobs = 2\n",
      "Launching Job 1 out of 2\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685819908924_0027, Tracking URL = http://e29ee468bf5f:8088/proxy/application_1685819908924_0027/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685819908924_0027\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 21:41:57,084 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-06-03 21:42:02,279 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.28 sec\n",
      "2023-06-03 21:42:08,471 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.95 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 950 msec\n",
      "Ended Job = job_1685819908924_0027\n",
      "Launching Job 2 out of 2\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685819908924_0028, Tracking URL = http://e29ee468bf5f:8088/proxy/application_1685819908924_0028/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685819908924_0028\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 21:42:21,974 Stage-2 map = 0%,  reduce = 0%\n",
      "2023-06-03 21:42:29,369 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.4 sec\n",
      "2023-06-03 21:42:35,551 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 5.06 sec\n",
      "MapReduce Total cumulative CPU time: 5 seconds 60 msec\n",
      "Ended Job = job_1685819908924_0028\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.95 sec   HDFS Read: 12378 HDFS Write: 1776 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 5.06 sec   HDFS Read: 7876 HDFS Write: 1500 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 10 seconds 10 msec\n",
      "OK\n",
      "a\taaa\t5\n",
      "a\tbbb\t7\n",
      "a\tccc\t13\n",
      "a\tddd\t13\n",
      "a\teee\t7\n",
      "a\tfff\t10\n",
      "a\tggg\t8\n",
      "a\thhh\t8\n",
      "a\tiii\t7\n",
      "a\tjjj\t10\n",
      "b\taaa\t4\n",
      "b\tbbb\t7\n",
      "b\tccc\t5\n",
      "b\tddd\t7\n",
      "b\teee\t5\n",
      "b\tfff\t8\n",
      "b\tggg\t4\n",
      "b\thhh\t7\n",
      "b\tiii\t7\n",
      "b\tjjj\t5\n",
      "c\taaa\t5\n",
      "c\tbbb\t4\n",
      "c\tccc\t12\n",
      "c\tddd\t9\n",
      "c\teee\t6\n",
      "c\tfff\t8\n",
      "c\tggg\t7\n",
      "c\thhh\t7\n",
      "c\tiii\t8\n",
      "c\tjjj\t8\n",
      "d\taaa\t4\n",
      "d\tbbb\t6\n",
      "d\tccc\t7\n",
      "d\tddd\t5\n",
      "d\teee\t6\n",
      "d\tfff\t8\n",
      "d\tggg\t6\n",
      "d\thhh\t4\n",
      "d\tiii\t9\n",
      "d\tjjj\t8\n",
      "e\taaa\t3\n",
      "e\tbbb\t8\n",
      "e\tccc\t9\n",
      "e\tddd\t7\n",
      "e\teee\t7\n",
      "e\tfff\t9\n",
      "e\tggg\t4\n",
      "e\thhh\t4\n",
      "e\tiii\t8\n",
      "e\tjjj\t3\n",
      "f\taaa\t8\n",
      "f\tbbb\t10\n",
      "f\tccc\t13\n",
      "f\tddd\t17\n",
      "f\teee\t11\n",
      "f\tfff\t11\n",
      "f\tggg\t9\n",
      "f\thhh\t10\n",
      "f\tiii\t10\n",
      "f\tjjj\t12\n",
      "g\taaa\t3\n",
      "g\tbbb\t3\n",
      "g\tccc\t6\n",
      "g\tddd\t5\n",
      "g\teee\t4\n",
      "g\tfff\t5\n",
      "g\tggg\t4\n",
      "g\thhh\t3\n",
      "g\tiii\t4\n",
      "g\tjjj\t6\n",
      "Time taken: 49.552 seconds, Fetched: 70 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "select letra, unal.key, count(1) \n",
    "from(\n",
    "select letra, c3\n",
    "from t0\n",
    "lateral view explode(c2) t0 as letra\n",
    "order by letra) w\n",
    "lateral view explode(c3) unal AS key, value\n",
    "group by letra, unal.key;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8968a-256c-4c57-8105-58ce414221e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
