{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37322a60-ebbb-45ef-ad1a-f59b58253aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import Magics, cell_magic, line_magic, magics_class\n",
    "from pexpect import spawn\n",
    "\n",
    "TIMEOUT = 300\n",
    "PROG = \"hive\"\n",
    "PROMPT = [\"\\r\\n    > \", \"\\r\\nhive> \"]\n",
    "QUIT = \"quit;\"\n",
    "\n",
    "\n",
    "@magics_class\n",
    "class Magic(Magics):\n",
    "    def __init__(self, shell):\n",
    "        super().__init__(shell)\n",
    "        self.app = spawn(PROG, timeout=60)\n",
    "        self.app.expect(PROMPT)\n",
    "\n",
    "    @cell_magic\n",
    "    def hive(self, line, cell):\n",
    "        cell_lines = [cell_line.strip() for cell_line in cell.split(\"\\n\")]\n",
    "        cell_lines = [cell_line for cell_line in cell_lines if cell_line != \"\"]\n",
    "        for cell_line in cell_lines:\n",
    "            self.app.sendline(cell_line)\n",
    "            self.app.expect(PROMPT, timeout=TIMEOUT)\n",
    "            output = self.app.before.decode()\n",
    "            output = output.replace(\"\\r\\n\", \"\\n\")\n",
    "            output = output.split(\"\\n\")\n",
    "            output = [output_line.strip() for output_line in output]\n",
    "            for output_line in output:\n",
    "                if output_line not in cell_lines:\n",
    "                    print(output_line)\n",
    "        return None\n",
    "\n",
    "    @line_magic\n",
    "    def quit(self, line):\n",
    "        self.app.sendline(QUIT)\n",
    "\n",
    "\n",
    "def load_ipython_extension(ip):\n",
    "    ip.register_magics(Magic(ip))\n",
    "\n",
    "\n",
    "load_ipython_extension(ip=get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd819e-2edc-433d-83f4-9c69e6066d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_02/data.tsv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34d658-1488-4dc2-a566-19dc3f4a1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2083c6-977c-423a-8dac-d0e99eb8225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm /tmp/data.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8be9b-815b-4ee0-88d8-fc38b0dd2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d78af-225a-4722-99b4-2ed8b7e18f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "CREATE TABLE data (\n",
    "letter STRING,\n",
    "date_event STRING,\n",
    "value INT\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY  '\\t';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee07e9-71f9-4720-ac07-9426b9342151",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "LOAD DATA INPATH '/tmp/data.tsv' OVERWRITE INTO TABLE data;\n",
    "SELECT * FROM data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eebb39-7014-447a-943c-1beb55eb47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT DISTINCT(value)\n",
    "FROM data\n",
    "ORDER BY value LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a24d1-e4f1-4413-b018-f69932d84b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT DISTINCT(letras) as let\n",
    "FROM(\n",
    "SELECT\n",
    "explode(c5) as letras\n",
    "FROM\n",
    "tbl0\n",
    ") w;\n",
    "ORDER BY let"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf53e343-a78d-42f6-a3a3-645d8b491c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_04/data0.csv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58da2cf5-5e2d-4165-9da1-b6c7e5454b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_04/data1.csv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5523e8ac-0f38-4eaa-b1cb-8d583e481681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\n",
      "-rw-r--r--   1 root supergroup        397 2023-06-03 15:23 /tmp/data0.csv\n",
      "-rw-r--r--   1 root supergroup        282 2023-06-03 15:23 /tmp/data1.csv\n",
      "drwxrwx---   - root supergroup          0 2023-06-03 15:20 /tmp/hadoop-yarn\n",
      "drwxrwxrwx   - root supergroup          0 2023-06-03 15:22 /tmp/hive\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca92ca78-5096-4ccf-b694-dc139db36aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Time taken: 11.383 seconds\n",
      "OK\n",
      "Time taken: 1.123 seconds\n",
      "Loading data to table default.tbl0\n",
      "OK\n",
      "Time taken: 1.278 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS tbl0;\n",
    "CREATE TABLE tbl0 (\n",
    "    c1 INT,\n",
    "    c2 STRING,\n",
    "    c3 INT,\n",
    "    c4 DATE,\n",
    "    c5 ARRAY<CHAR(1)>, \n",
    "    c6 MAP<STRING, INT>\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ','\n",
    "COLLECTION ITEMS TERMINATED BY ':'\n",
    "MAP KEYS TERMINATED BY '#'\n",
    "LINES TERMINATED BY '\\n';\n",
    "LOAD DATA INPATH '/tmp/data0.csv' INTO TABLE tbl0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e239234b-f2b7-4460-85ee-d24497ac803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "tbl0\n",
      "Time taken: 0.255 seconds, Fetched: 1 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SHOW TABLES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6e8451b-d790-41cd-8937-e31801b2e8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILED: SemanticException 4:9 SELECT DISTINCT and GROUP BY can not be in the same query. Error encountered near token 'letras'\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT SUBSTRING(c4,0,4) as c4, letras, count(1) FROM tbl0\n",
    "LATERAL VIEW\n",
    "    explode(c5) tbl0 as letras\n",
    "GROUP BY c4, letras;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6908264f-a6b4-429a-86a8-48d013b0ff32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230603161039_e51c8d54-5dec-4db9-b4f7-7f998bc5e624\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685805632661_0018, Tracking URL = http://6c0dee391b46:8088/proxy/application_1685805632661_0018/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685805632661_0018\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 16:10:47,160 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-06-03 16:10:52,328 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.93 sec\n",
      "2023-06-03 16:10:57,481 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.3 sec\n",
      "MapReduce Total cumulative CPU time: 5 seconds 300 msec\n",
      "Ended Job = job_1685805632661_0018\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.3 sec   HDFS Read: 9296 HDFS Write: 172 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 5 seconds 300 msec\n",
      "OK\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "Time taken: 20.083 seconds, Fetched: 5 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT DISTINCT(SUBSTRING(c4,0,4)) as c4 FROM tbl0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eabccc-7b22-47b9-a51b-046f9f9ade1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT explode(split(c5, ',')) AS word FROM tbl0 LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "469f0d0d-5802-4365-9e68-2334d7e10b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoViableAltException(135@[])\n",
      "at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1300)\n",
      "at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:208)\n",
      "at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:77)\n",
      "at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:70)\n",
      "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:468)\n",
      "at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1317)\n",
      "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1457)\n",
      "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)\n",
      "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:233)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:184)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:403)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:821)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:759)\n",
      "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:686)\n",
      "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "at java.lang.reflect.Method.invoke(Method.java:498)\n",
      "at org.apache.hadoop.util.RunJar.run(RunJar.java:244)\n",
      "at org.apache.hadoop.util.RunJar.main(RunJar.java:158)\n",
      "FAILED: ParseException line 1:0 cannot recognize input near 'GROUP' 'BY' 'letras'\n",
      "FAILED: SemanticException [Error 10025]: Line 1:7 Expression not in GROUP BY key 'otro'\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT otro, letras, count(*) as total FROM(\n",
    "SELECT SUBSTRING(c4,0,4) as otro, letras FROM tbl0\n",
    "LATERAL VIEW\n",
    "    explode(c5) tbl0 as letras\n",
    "ORDER BY otro, letras\n",
    ") w;\n",
    "GROUP BY otro, letras;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d0197317-70fc-4206-8015-dfc2f1e579c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230603161921_1c0847db-9b84-4b02-bbb8-0494f43db67b\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685805632661_0020, Tracking URL = http://6c0dee391b46:8088/proxy/application_1685805632661_0020/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685805632661_0020\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 16:19:29,472 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-06-03 16:19:34,661 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.18 sec\n",
      "2023-06-03 16:19:40,864 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.55 sec\n",
      "MapReduce Total cumulative CPU time: 5 seconds 550 msec\n",
      "Ended Job = job_1685805632661_0020\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.55 sec   HDFS Read: 12791 HDFS Write: 507 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 5 seconds 550 msec\n",
      "OK\n",
      "2014\ta\t1\n",
      "2014\tb\t1\n",
      "2014\td\t2\n",
      "2014\te\t1\n",
      "2015\ta\t3\n",
      "2015\tb\t1\n",
      "2015\tc\t3\n",
      "2015\td\t2\n",
      "2015\te\t2\n",
      "2016\ta\t2\n",
      "2016\tb\t1\n",
      "2016\tc\t3\n",
      "2016\td\t3\n",
      "2016\te\t3\n",
      "2017\ta\t1\n",
      "2017\tb\t1\n",
      "2017\tc\t1\n",
      "2017\te\t1\n",
      "2018\ta\t1\n",
      "2018\td\t1\n",
      "Time taken: 20.337 seconds, Fetched: 20 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT otro, letras, count(*) as total FROM(\n",
    "SELECT SUBSTRING(c4,0,4) as otro, letras FROM tbl0\n",
    "LATERAL VIEW\n",
    "    explode(c5) tbl0 as letras\n",
    "ORDER BY otro, letras\n",
    ") w\n",
    "GROUP BY otro, letras;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5742993-e834-4176-ae58-fcfb6c208231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
