{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37322a60-ebbb-45ef-ad1a-f59b58253aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import Magics, cell_magic, line_magic, magics_class\n",
    "from pexpect import spawn\n",
    "\n",
    "TIMEOUT = 300\n",
    "PROG = \"hive\"\n",
    "PROMPT = [\"\\r\\n    > \", \"\\r\\nhive> \"]\n",
    "QUIT = \"quit;\"\n",
    "\n",
    "\n",
    "@magics_class\n",
    "class Magic(Magics):\n",
    "    def __init__(self, shell):\n",
    "        super().__init__(shell)\n",
    "        self.app = spawn(PROG, timeout=60)\n",
    "        self.app.expect(PROMPT)\n",
    "\n",
    "    @cell_magic\n",
    "    def hive(self, line, cell):\n",
    "        cell_lines = [cell_line.strip() for cell_line in cell.split(\"\\n\")]\n",
    "        cell_lines = [cell_line for cell_line in cell_lines if cell_line != \"\"]\n",
    "        for cell_line in cell_lines:\n",
    "            self.app.sendline(cell_line)\n",
    "            self.app.expect(PROMPT, timeout=TIMEOUT)\n",
    "            output = self.app.before.decode()\n",
    "            output = output.replace(\"\\r\\n\", \"\\n\")\n",
    "            output = output.split(\"\\n\")\n",
    "            output = [output_line.strip() for output_line in output]\n",
    "            for output_line in output:\n",
    "                if output_line not in cell_lines:\n",
    "                    print(output_line)\n",
    "        return None\n",
    "\n",
    "    @line_magic\n",
    "    def quit(self, line):\n",
    "        self.app.sendline(QUIT)\n",
    "\n",
    "\n",
    "def load_ipython_extension(ip):\n",
    "    ip.register_magics(Magic(ip))\n",
    "\n",
    "\n",
    "load_ipython_extension(ip=get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd819e-2edc-433d-83f4-9c69e6066d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_02/data.tsv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34d658-1488-4dc2-a566-19dc3f4a1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2083c6-977c-423a-8dac-d0e99eb8225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm /tmp/data.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8be9b-815b-4ee0-88d8-fc38b0dd2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d78af-225a-4722-99b4-2ed8b7e18f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "CREATE TABLE data (\n",
    "letter STRING,\n",
    "date_event STRING,\n",
    "value INT\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY  '\\t';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee07e9-71f9-4720-ac07-9426b9342151",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "LOAD DATA INPATH '/tmp/data.tsv' OVERWRITE INTO TABLE data;\n",
    "SELECT * FROM data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eebb39-7014-447a-943c-1beb55eb47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT DISTINCT(value)\n",
    "FROM data\n",
    "ORDER BY value LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a24d1-e4f1-4413-b018-f69932d84b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT DISTINCT(letras) as let\n",
    "FROM(\n",
    "SELECT\n",
    "explode(c5) as letras\n",
    "FROM\n",
    "tbl0\n",
    ") w;\n",
    "ORDER BY let"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf53e343-a78d-42f6-a3a3-645d8b491c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_04/data0.csv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58da2cf5-5e2d-4165-9da1-b6c7e5454b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal pregunta_04/data1.csv /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5523e8ac-0f38-4eaa-b1cb-8d583e481681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\n",
      "-rw-r--r--   1 root supergroup        397 2023-06-03 15:23 /tmp/data0.csv\n",
      "-rw-r--r--   1 root supergroup        282 2023-06-03 15:23 /tmp/data1.csv\n",
      "drwxrwx---   - root supergroup          0 2023-06-03 15:20 /tmp/hadoop-yarn\n",
      "drwxrwxrwx   - root supergroup          0 2023-06-03 15:22 /tmp/hive\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca92ca78-5096-4ccf-b694-dc139db36aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Time taken: 11.383 seconds\n",
      "OK\n",
      "Time taken: 1.123 seconds\n",
      "Loading data to table default.tbl0\n",
      "OK\n",
      "Time taken: 1.278 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS tbl0;\n",
    "CREATE TABLE tbl0 (\n",
    "    c1 INT,\n",
    "    c2 STRING,\n",
    "    c3 INT,\n",
    "    c4 DATE,\n",
    "    c5 ARRAY<CHAR(1)>, \n",
    "    c6 MAP<STRING, INT>\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ','\n",
    "COLLECTION ITEMS TERMINATED BY ':'\n",
    "MAP KEYS TERMINATED BY '#'\n",
    "LINES TERMINATED BY '\\n';\n",
    "LOAD DATA INPATH '/tmp/data0.csv' INTO TABLE tbl0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e239234b-f2b7-4460-85ee-d24497ac803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "tbl0\n",
      "Time taken: 0.255 seconds, Fetched: 1 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SHOW TABLES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6908264f-a6b4-429a-86a8-48d013b0ff32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230603161039_e51c8d54-5dec-4db9-b4f7-7f998bc5e624\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685805632661_0018, Tracking URL = http://6c0dee391b46:8088/proxy/application_1685805632661_0018/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685805632661_0018\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 16:10:47,160 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-06-03 16:10:52,328 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.93 sec\n",
      "2023-06-03 16:10:57,481 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.3 sec\n",
      "MapReduce Total cumulative CPU time: 5 seconds 300 msec\n",
      "Ended Job = job_1685805632661_0018\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.3 sec   HDFS Read: 9296 HDFS Write: 172 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 5 seconds 300 msec\n",
      "OK\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "Time taken: 20.083 seconds, Fetched: 5 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT DISTINCT(SUBSTRING(c4,0,4)) as c4 FROM tbl0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eabccc-7b22-47b9-a51b-046f9f9ade1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%hive\n",
    "SELECT explode(split(c5, ',')) AS word FROM tbl0 LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d0197317-70fc-4206-8015-dfc2f1e579c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230603161921_1c0847db-9b84-4b02-bbb8-0494f43db67b\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685805632661_0020, Tracking URL = http://6c0dee391b46:8088/proxy/application_1685805632661_0020/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685805632661_0020\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 16:19:29,472 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-06-03 16:19:34,661 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.18 sec\n",
      "2023-06-03 16:19:40,864 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.55 sec\n",
      "MapReduce Total cumulative CPU time: 5 seconds 550 msec\n",
      "Ended Job = job_1685805632661_0020\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.55 sec   HDFS Read: 12791 HDFS Write: 507 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 5 seconds 550 msec\n",
      "OK\n",
      "2014\ta\t1\n",
      "2014\tb\t1\n",
      "2014\td\t2\n",
      "2014\te\t1\n",
      "2015\ta\t3\n",
      "2015\tb\t1\n",
      "2015\tc\t3\n",
      "2015\td\t2\n",
      "2015\te\t2\n",
      "2016\ta\t2\n",
      "2016\tb\t1\n",
      "2016\tc\t3\n",
      "2016\td\t3\n",
      "2016\te\t3\n",
      "2017\ta\t1\n",
      "2017\tb\t1\n",
      "2017\tc\t1\n",
      "2017\te\t1\n",
      "2018\ta\t1\n",
      "2018\td\t1\n",
      "Time taken: 20.337 seconds, Fetched: 20 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT otro, letras, count(*) as total FROM(\n",
    "SELECT SUBSTRING(c4,0,4) as otro, letras FROM tbl0\n",
    "LATERAL VIEW\n",
    "    explode(c5) tbl0 as letras\n",
    "ORDER BY otro, letras\n",
    ") w\n",
    "GROUP BY otro, letras;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a5742993-e834-4176-ae58-fcfb6c208231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230603164742_9f93e867-e76e-425f-9954-207ba7cd439e\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685805632661_0022, Tracking URL = http://6c0dee391b46:8088/proxy/application_1685805632661_0022/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685805632661_0022\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 16:47:50,967 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-06-03 16:47:56,130 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.65 sec\n",
      "2023-06-03 16:48:02,311 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.61 sec\n",
      "MapReduce Total cumulative CPU time: 5 seconds 610 msec\n",
      "Ended Job = job_1685805632661_0022\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.61 sec   HDFS Read: 12120 HDFS Write: 109 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 5 seconds 610 msec\n",
      "OK\n",
      "[\"A\",\"E\",\"C\",\"D\",\"B\"]\n",
      "Time taken: 20.793 seconds, Fetched: 1 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT COLLECT_SET(UPPER(letras)) FROM tbl0\n",
    "LATERAL VIEW\n",
    "    explode(c5) tbl0 as letras;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0cad85c0-d857-4086-ad6a-4a5b099bb9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "A:E:C:D\n",
      "A:C\n",
      "B:D\n",
      "A:C:E:B:D\n",
      "D:E:C\n",
      "A:D\n",
      "A:E:D\n",
      "D:A:C:E\n",
      "B:A:C:E\n",
      "C:D:E:A:B\n",
      "Time taken: 0.11 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT UPPER(CONCAT_WS(':',c5)) FROM tbl0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c1553665-873d-467b-9d6a-e624f64a3ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID = root_20230603170641_8295f7b4-ffc5-44a3-a920-2a3f956f39db\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1685805632661_0026, Tracking URL = http://6c0dee391b46:8088/proxy/application_1685805632661_0026/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1685805632661_0026\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2023-06-03 17:06:49,153 Stage-1 map = 0%,  reduce = 0%\n",
      "2023-06-03 17:06:54,312 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.26 sec\n",
      "2023-06-03 17:07:00,465 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.26 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 260 msec\n",
      "Ended Job = job_1685805632661_0026\n",
      "MapReduce Jobs Launched:\n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.26 sec   HDFS Read: 10082 HDFS Write: 164 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 4 seconds 260 msec\n",
      "OK\n",
      "A\t[6]\n",
      "B\t[7,9,10]\n",
      "C\t[2,5,8]\n",
      "D\t[1,3,4]\n",
      "Time taken: 20.145 seconds, Fetched: 4 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT c2, COLLECT_SET(c1) FROM tbl0\n",
    "GROUP BY c2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f6040-afe3-428e-9969-62c84b1bd636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
